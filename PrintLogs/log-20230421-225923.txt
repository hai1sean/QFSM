Input dim:    64
LSTM output size: 64
Number of qubits: 4
Training epochs:  200
Batch_size:       200
Num_rounds:       50
Local_epochs:       5
Tagger will use Quantum MGU running on backend default.qubit
weight_shapes = (n_qlayers, n_qubits) = (1, 4)
batch 1, loss 2.7844018936157227, batch_time 0m 34s
batch 2, loss 2.7949771881103516, batch_time 1m 9s
batch 3, loss 2.7396023273468018, batch_time 1m 43s
batch 4, loss 2.6884970664978027, batch_time 2m 18s
batch 5, loss 2.7112035751342773, batch_time 2m 54s
batch 6, loss 2.730621814727783, batch_time 3m 29s
batch 7, loss 2.6493403911590576, batch_time 4m 8s
batch 8, loss 2.6763663291931152, batch_time 4m 43s
batch 9, loss 2.6606225967407227, batch_time 5m 18s
batch 10, loss 2.6473143100738525, batch_time 5m 39s
C:\Users\swk\Anaconda3\envs\swk01\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Validation confusion matrix:
[[  0 168   0]
 [  0 232   0]
 [  0  80   0]]
Validation precision: 0.2336
Validation recall: 0.4833
Validation F1 score: 0.3150
Epoch 1 / 200: Loss = 2.70829 Acc = 0.50417  Valid_acc = 0.4833333194255829 lr = 0.00100 Training complete in 6m 38s'
batch 1, loss 2.6334402561187744, batch_time 0m 39s
batch 2, loss 2.6685914993286133, batch_time 1m 14s
batch 3, loss 2.5913889408111572, batch_time 1m 49s
batch 4, loss 2.535736322402954, batch_time 2m 24s
batch 5, loss 2.5660135746002197, batch_time 2m 59s
batch 6, loss 2.598123550415039, batch_time 3m 34s
batch 7, loss 2.512308359146118, batch_time 4m 9s
batch 8, loss 2.5486111640930176, batch_time 4m 44s
batch 9, loss 2.5374443531036377, batch_time 5m 19s
batch 10, loss 2.5245728492736816, batch_time 5m 40s
C:\Users\swk\Anaconda3\envs\swk01\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Validation confusion matrix:
[[  0 168   0]
 [  0 232   0]
 [  0  80   0]]
Validation precision: 0.2336
Validation recall: 0.4833
Validation F1 score: 0.3150
Epoch 2 / 200: Loss = 2.57162 Acc = 0.50417  Valid_acc = 0.4833333194255829 lr = 0.00100 Training complete in 6m 39s'
batch 1, loss 2.509268283843994, batch_time 0m 35s
batch 2, loss 2.55578351020813, batch_time 1m 10s
batch 3, loss 2.4679226875305176, batch_time 1m 45s
batch 4, loss 2.4107818603515625, batch_time 2m 20s
batch 5, loss 2.4439663887023926, batch_time 2m 54s
batch 6, loss 2.4807910919189453, batch_time 3m 29s
